{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:25:30.972907Z","iopub.execute_input":"2024-07-16T08:25:30.973673Z","iopub.status.idle":"2024-07-16T08:25:36.375537Z","shell.execute_reply.started":"2024-07-16T08:25:30.973642Z","shell.execute_reply":"2024-07-16T08:25:36.374741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:25:36.376929Z","iopub.execute_input":"2024-07-16T08:25:36.377471Z","iopub.status.idle":"2024-07-16T08:25:36.415941Z","shell.execute_reply.started":"2024-07-16T08:25:36.377445Z","shell.execute_reply":"2024-07-16T08:25:36.414652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation for training\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       torchvision.transforms.AutoAugment(torchvision.transforms.AutoAugmentPolicy.IMAGENET),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n# Data augmentation for testing\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:25:36.417121Z","iopub.execute_input":"2024-07-16T08:25:36.417697Z","iopub.status.idle":"2024-07-16T08:25:36.435203Z","shell.execute_reply.started":"2024-07-16T08:25:36.417666Z","shell.execute_reply":"2024-07-16T08:25:36.434324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = torchvision.models.DenseNet201_Weights.DEFAULT\nautomatic_transforms = weights.transforms() \nprint(f\"Automatically created transforms: {automatic_transforms}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:25:36.437289Z","iopub.execute_input":"2024-07-16T08:25:36.437687Z","iopub.status.idle":"2024-07-16T08:25:36.446847Z","shell.execute_reply.started":"2024-07-16T08:25:36.437657Z","shell.execute_reply":"2024-07-16T08:25:36.445927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\n\nfrom pathlib import Path\ndata_dir = Path(\"data\")\n\ntrain_data = datasets.Food101(root=data_dir,split=\"train\",transform=None,download=True)\ntest_data = datasets.Food101(root=data_dir,split=\"test\",transform=None,download=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:25:36.447847Z","iopub.execute_input":"2024-07-16T08:25:36.448122Z","iopub.status.idle":"2024-07-16T08:30:02.115133Z","shell.execute_reply.started":"2024-07-16T08:25:36.448101Z","shell.execute_reply":"2024-07-16T08:30:02.113872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/data/food-101.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:30:22.451809Z","iopub.execute_input":"2024-07-16T08:30:22.452865Z","iopub.status.idle":"2024-07-16T08:30:24.123733Z","shell.execute_reply.started":"2024-07-16T08:30:22.452833Z","shell.execute_reply":"2024-07-16T08:30:24.122488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom torchvision import transforms\ntrain_dir = data_dir / \"train\"\ntest_dir = data_dir / \"test\"\ntrain_dir.mkdir(parents=True, exist_ok=True)\ntest_dir.mkdir(parents=True, exist_ok=True)\n\ndef save_all_images(dataset, save_dir):\n    for idx, (image, label) in enumerate(dataset):\n        class_name = dataset.classes[label]\n        # Create a subdirectory for the class if it doesn't exist\n        class_dir = save_dir / class_name\n        class_dir.mkdir(parents=True, exist_ok=True)\n        \n        save_path = class_dir / f\"{idx}.jpg\"\n        image.save(save_path)\n\nsave_all_images(train_data, train_dir)\nsave_all_images(test_data, test_dir)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:31:26.614932Z","iopub.execute_input":"2024-07-16T08:31:26.615352Z","iopub.status.idle":"2024-07-16T08:36:08.272400Z","shell.execute_reply.started":"2024-07-16T08:31:26.615300Z","shell.execute_reply":"2024-07-16T08:36:08.271480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\n\nfrom pathlib import Path\ndata_dir = Path(\"data\")\n\ntrain_data_manual = datasets.ImageFolder(train_dir,transform=train_transforms)\ntest_data_manual = datasets.ImageFolder(test_dir,transform=test_transforms)\nclass_names_manual = train_data_manual.classes","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:17.662937Z","iopub.execute_input":"2024-07-16T08:36:17.663336Z","iopub.status.idle":"2024-07-16T08:36:18.114259Z","shell.execute_reply.started":"2024-07-16T08:36:17.663306Z","shell.execute_reply":"2024-07-16T08:36:18.113297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\n\nfrom pathlib import Path\ndata_dir = Path(\"data\")\n\ntrain_data_auto = datasets.ImageFolder(train_dir,transform=automatic_transforms)\ntest_data_auto = datasets.ImageFolder(test_dir,transform=automatic_transforms)\nclass_names_auto = train_data_auto.classes","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:27.017693Z","iopub.execute_input":"2024-07-16T08:36:27.018165Z","iopub.status.idle":"2024-07-16T08:36:27.481231Z","shell.execute_reply.started":"2024-07-16T08:36:27.018125Z","shell.execute_reply":"2024-07-16T08:36:27.480278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_manual","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:27.796826Z","iopub.execute_input":"2024-07-16T08:36:27.797478Z","iopub.status.idle":"2024-07-16T08:36:27.803584Z","shell.execute_reply.started":"2024-07-16T08:36:27.797445Z","shell.execute_reply":"2024-07-16T08:36:27.802719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_auto","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:29.232598Z","iopub.execute_input":"2024-07-16T08:36:29.233293Z","iopub.status.idle":"2024-07-16T08:36:29.238939Z","shell.execute_reply.started":"2024-07-16T08:36:29.233260Z","shell.execute_reply":"2024-07-16T08:36:29.237958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom torch.utils.data import DataLoader\nnum_workers = os.cpu_count()\ntrain_dataloader_manual = DataLoader(\n      train_data_manual,\n      batch_size=32,\n      shuffle=True,\n      num_workers=num_workers,\n      pin_memory=True,\n  )\ntest_dataloader_manual = DataLoader(\n      test_data_manual,\n      batch_size=32,\n      shuffle=False,\n      num_workers=num_workers,\n      pin_memory=True,\n  )\n\ntrain_dataloader_auto = DataLoader(\n      test_data_auto,\n      batch_size=32,\n      shuffle=True,\n      num_workers=num_workers,\n      pin_memory=True,\n  )\ntest_dataloader_auto = DataLoader(\n      test_data_auto,\n      batch_size=32,\n      shuffle=False,\n      num_workers=num_workers,\n      pin_memory=True,\n  )","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:30.859809Z","iopub.execute_input":"2024-07-16T08:36:30.860421Z","iopub.status.idle":"2024-07-16T08:36:30.867451Z","shell.execute_reply.started":"2024-07-16T08:36:30.860390Z","shell.execute_reply":"2024-07-16T08:36:30.866576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\nweights = models.DenseNet201_Weights.IMAGENET1K_V1\nmodel = models.densenet201(weights = weights).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:33.656399Z","iopub.execute_input":"2024-07-16T08:36:33.657287Z","iopub.status.idle":"2024-07-16T08:36:35.405151Z","shell.execute_reply.started":"2024-07-16T08:36:33.657247Z","shell.execute_reply":"2024-07-16T08:36:35.404360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set seeds\ndef set_seeds(seed: int=42):\n    \"\"\"Sets random sets for torch operations.\n\n    Args:\n        seed (int, optional): Random seed to set. Defaults to 42.\n    \"\"\"\n    # Set the seed for general torch operations\n    torch.manual_seed(seed)\n    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n    torch.cuda.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:43.072508Z","iopub.execute_input":"2024-07-16T08:36:43.073142Z","iopub.status.idle":"2024-07-16T08:36:43.078130Z","shell.execute_reply.started":"2024-07-16T08:36:43.073111Z","shell.execute_reply":"2024-07-16T08:36:43.077272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all base layers by setting requires_grad attribute to False\nfor param in model.features.parameters():\n    param.requires_grad = False\n    \n# Since we're creating a new layer with random weights (torch.nn.Linear), \n# let's set the seeds\nset_seeds() \n\n# Update the classifier head to suit our problem\nmodel.classifier = torch.nn.Sequential(\n    nn.Dropout(p=0.2, inplace=True),\n    nn.Linear(in_features=1920, \n              out_features=len(class_names_manual),\n              bias=True).to(device))","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:44.463661Z","iopub.execute_input":"2024-07-16T08:36:44.464273Z","iopub.status.idle":"2024-07-16T08:36:44.476232Z","shell.execute_reply.started":"2024-07-16T08:36:44.464240Z","shell.execute_reply":"2024-07-16T08:36:44.475456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\n# # Get a summary of the model (uncomment for full output)\nsummary(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:45.744463Z","iopub.execute_input":"2024-07-16T08:36:45.745134Z","iopub.status.idle":"2024-07-16T08:36:45.816906Z","shell.execute_reply.started":"2024-07-16T08:36:45.745104Z","shell.execute_reply":"2024-07-16T08:36:45.816039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:46.715774Z","iopub.execute_input":"2024-07-16T08:36:46.716361Z","iopub.status.idle":"2024-07-16T08:36:46.724890Z","shell.execute_reply.started":"2024-07-16T08:36:46.716327Z","shell.execute_reply":"2024-07-16T08:36:46.723922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device):\n  # Put model in train mode\n  model.train()\n\n  # Setup train loss and train accuracy values\n  train_loss, train_acc = 0, 0\n\n  print(\"--> Training Progress\")\n  # Loop through data loader data batches\n  for batch, (X, y) in enumerate(tqdm(dataloader)):\n      # Send data to target device\n      images, labels = X.to(device), y.to(device)\n\n      # 1. Forward pass\n      y_pred = model(images)\n\n      # 2. Calculate  and accumulate loss\n      loss = loss_fn(y_pred, labels)\n      train_loss += loss.item()\n\n      # 3. Optimizer zero grad\n      optimizer.zero_grad()\n\n      # 4. Loss backward\n      loss.backward()\n\n      # 5. Optimizer step\n      optimizer.step()\n\n      # Calculate and accumulate accuracy metric across all batches\n      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n      train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n\n  # Adjust metrics to get average loss and accuracy per batch\n  train_loss = train_loss / len(dataloader)\n  train_acc = train_acc / len(dataloader)\n  return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:47.877437Z","iopub.execute_input":"2024-07-16T08:36:47.878048Z","iopub.status.idle":"2024-07-16T08:36:47.886867Z","shell.execute_reply.started":"2024-07-16T08:36:47.878018Z","shell.execute_reply":"2024-07-16T08:36:47.885893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device):\n  # Put model in eval mode\n  model.eval()\n\n  # Setup test loss and test accuracy values\n  test_loss, test_acc = 0, 0\n\n  # Turn on inference context manager\n  with torch.inference_mode():\n      print(\"--> Testing Progress\")\n      # Loop through DataLoader batches\n      for batch, (X, y) in enumerate(tqdm(dataloader)):\n          # Send data to target device\n          images, labels = X.to(device), y.to(device)\n\n          # 1. Forward pass\n          test_pred_logits = model(images)\n\n          # 2. Calculate and accumulate loss\n          loss = loss_fn(test_pred_logits, labels)\n          test_loss += loss.item()\n\n          # Calculate and accumulate accuracy\n          test_pred_labels = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n\n          test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n\n  # Adjust metrics to get average loss and accuracy per batch\n  test_loss = test_loss / len(dataloader)\n  test_acc = test_acc / len(dataloader)\n  return test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:48.829552Z","iopub.execute_input":"2024-07-16T08:36:48.830172Z","iopub.status.idle":"2024-07-16T08:36:48.838630Z","shell.execute_reply.started":"2024-07-16T08:36:48.830141Z","shell.execute_reply":"2024-07-16T08:36:48.837697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Dict, List, Tuple\nfrom tqdm.auto import tqdm\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n               \"train_acc\": [],\n               \"test_loss\": [],\n               \"test_acc\": []\n    }\n    \n    # Make sure model on target device\n    model.to(device)\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n        test_loss, test_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n        # Print out what's happening\n        print(\n          f\"Epoch: {epoch+1} | \"\n          f\"train_loss: {train_loss:.4f} | \"\n          f\"train_acc: {train_acc:.4f} | \"\n          f\"test_loss: {test_loss:.4f} | \"\n          f\"test_acc: {test_acc:.4f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n\n    # Return the filled results at the end of the epochs\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:36:53.593674Z","iopub.execute_input":"2024-07-16T08:36:53.594452Z","iopub.status.idle":"2024-07-16T08:36:53.605385Z","shell.execute_reply.started":"2024-07-16T08:36:53.594418Z","shell.execute_reply":"2024-07-16T08:36:53.604356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seeds()\nresults_manual = train(model, train_dataloader_manual, test_dataloader_manual, optimizer, loss_fn, 10, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:37:03.119889Z","iopub.execute_input":"2024-07-16T08:37:03.120308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out the model results\nresults_manual","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seeds()\nresults_auto = train(model, train_dataloader_auto, test_dataloader_auto, optimizer, loss_fn, 10, device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out the model results\nresults_auto","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Evaluate model by plotting loss curves***","metadata":{}},{"cell_type":"code","source":"def plot_loss_curves(results):\n    loss = results[\"train_loss\"]\n    test_loss = results[\"test_loss\"]\n\n    accuracy = results[\"train_acc\"]\n    test_accuracy = results[\"test_acc\"]\n\n    epochs = range(len(results[\"train_loss\"]))\n\n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label=\"train_loss\")\n    plt.plot(epochs, test_loss, label=\"test_loss\")\n    plt.title(\"Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n    plt.title(\"Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(results_manual)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(results_auto)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List, Tuple\n\nfrom PIL import Image\n\n# 1. Take in a trained model, class names, image path, image size, a transform and target device\ndef pred_and_plot_image(model: torch.nn.Module,\n                        image_path: str, \n                        class_names: List[str],\n                        image_size: Tuple[int, int] = (224, 224),\n                        transform: torchvision.transforms = None,\n                        device: torch.device=device):\n    \n    \n    # 2. Open image\n    img = Image.open(image_path)\n\n    # 3. Create transformation for image (if one doesn't exist)\n    if transform is not None:\n        image_transform = transform\n    else:\n        image_transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        ])\n\n    ### Predict on image ### \n\n    # 4. Make sure the model is on the target device\n    model.to(device)\n\n    # 5. Turn on model evaluation mode and inference mode\n    model.eval()\n    with torch.inference_mode():\n      # 6. Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n      transformed_image = image_transform(img).unsqueeze(dim=0)\n\n      # 7. Make a prediction on image with an extra dimension and send it to the target device\n      target_image_pred = model(transformed_image.to(device))\n\n    # 8. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n\n    # 9. Convert prediction probabilities -> prediction labels\n    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n\n    # 10. Plot image with predicted label and probability \n    plt.figure()\n    plt.imshow(img)\n    plt.title(f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\")\n    plt.axis(False);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a random list of image paths from test set\nimport random\nnum_images_to_plot = 3\ntest_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\")) # get list all image paths from test data \ntest_image_path_sample = random.sample(population=test_image_path_list, # go through all of the test image paths\n                                       k=num_images_to_plot) # randomly select 'k' image paths to pred and plot\n\n# Make predictions on and plot the images\nfor image_path in test_image_path_sample:\n    pred_and_plot_image(model=model, \n                        image_path=image_path,\n                        class_names=class_names_manual,\n                        # transform=weights.transforms(), # optionally pass in a specified transform from our pretrained model weights\n                        image_size=(224, 224))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download custom image\nimport requests\n\n# Setup custom image path\ncustom_image_path = data_dir / \"04-pizza-dad.jpeg\"\n\n# Download the image if it doesn't already exist\nif not custom_image_path.is_file():\n    with open(custom_image_path, \"wb\") as f:\n        # When downloading from GitHub, need to use the \"raw\" file link\n        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n        print(f\"Downloading {custom_image_path}...\")\n        f.write(request.content)\nelse:\n    print(f\"{custom_image_path} already exists, skipping download.\")\n\n# Predict on custom image\npred_and_plot_image(model=model,\n                    image_path=custom_image_path,\n                    class_names=class_names_manual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}